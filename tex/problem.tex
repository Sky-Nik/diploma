Для порівняння алгоритмів нам знадобляться тестові задачі різної складності та різних розмірів. У якості таких задачі розглянемо:

\section{Перша задача}

Класичний приклад. Допустимою множиною є увесь простір: $C = \RR^m$, а $F(x) = Ax$, де $A$ --- квадратна $m \times m$ матриця, елементи якої визначаються наступним чином:
\begin{equation}
    a_{i,j} = \begin{cases}
        -1, & j = m - 1 - i > i, \\
        1, & j = m - 1 - i < i, \\
        0, & \text{інакше}.
    \end{cases}
\end{equation}

\begin{remark}
    Тут і надалі нуметрація рядків/стовпчиків матриць, а також елементів масивів починається з нуля. Якщо у вашій мові програмування нумерація починається з одиниці то у виразах вище замість $m - 1$ має бути $m + 1$.
\end{remark}

Це визначає матрицю, чия бічна діагональ складається з половини одиниць і половини мінус одиниць, а решта елементів якої нульові. Для наглядності наведемо кілька преших матриць, для $m = 2, 4$:
\begin{equation}
    \begin{pmatrix}
        0 & -1 \\
        1 & 0
    \end{pmatrix}
    \qquad
    \begin{pmatrix}
        0 & 0 & 0 & -1 \\
        0 & 0 & -1 & 0 \\
        0 & 1 & 0 & 0 \\
        1 & 0 & 0 & 0
    \end{pmatrix}
    % \qquad
    % \begin{pmatrix}
    %     0 & 0 & 0 & 0 & 0 & -1 \\
    %     0 & 0 & 0 & 0 & -1 & 0 \\
    %     0 & 0 & 0 & -1 & 0 & 0 \\
    %     0 & 0 & 1 & 0 & 0 & 0 \\
    %     0 & 1 & 0 & 0 & 0 & 0 \\
    %     1 & 0 & 0 & 0 & 0 & 0
    % \end{pmatrix}
\end{equation}

Для парних $m$ нульовий вектор є розв'язком відповідної варіаційної нерівності \eqref{eq:variational-inequality}. Для усіх чисельних еспериментів ми брали $x_0 = (1, \dots, 1)$, $\epsilon = 10^{-3}$, $\lambda = 0.4$. 

\begin{remark}
    Ця задача є узагальненням \ref{classical-example}. Як ми вже знаємо, звичайні градієнтні методи для неї не збігаються.
\end{remark}

\begin{remark}
    Для цієї задачі $P_C = \text{Id}$, а тому алгоритми Корпелевич і Tseng'a еквівалентні. Втім, некешована версія алгоритму Tseng'a буде працювати повільніше, у чому ми переконаємося у результатах.
\end{remark}

\section{Друга задача}

Візьмемо $F(x) = M x + q$, де випадкова матриця $M$ генерується наступним чином:
\begin{equation}
    M = A A^\intercal + B + D,
\end{equation}
де всі елементи $m \times m$ матриці $A$ і $m \times m$ кососиметричної матриці $B$ обираються рівномірно випадково з $(-5, 5)$, а усі елементи діагональної матриці $D$ вибираються рівномірно випадково з $(0, 0.3)$ (як наслідок, матриця $M$ додатно визначена), а кожен елемент $q$ обирається рівномірно випадково з $(-500, 0)$. Допустимою множиною є 
\begin{equation}
    C = \left\{ x \in \RR_+^m \middle| x_1 + x_2 + \dots + x_m = m \right\}.
\end{equation}

Допустима множина цієї задачі --- так званий \emph{probability symplex} (з точністю до константи $m$). Для проектування $\vec y$ на нього ми використовували наступний явний
\begin{algorithm}\nothing

    \textbf{Крок 1.} Відсортувати елементи $\vec y$ і зберегти в $\vec u$: $u_1 \ge \dots \ge u_m$. \medskip
        
    \textbf{Крок 2.} Знайти $k = \max j$: $u_j + \frac{1}{j} \left( m - \Sum_{i = 1}^j u_i \right) > 0$. \medskip
        
    \textbf{Крок 3.} Видати вектор з елементами $x_i = \max\{y_i + \lambda, 0\}$, $\lambda = \frac{1}{k} \left( m - \Sum_{i = 1}^k u_i \right)$.
\end{algorithm}

\emph{Цей алгоритм взято із статті \cite{duchi-et-al}}. \medskip

Для усіх чисельних експериментів ми брали $x_0 = (1, \dots, 1)$, $\epsilon = 10^{-3}$, $L = \no{M}$. також, для кожного розмірку задачі було згенеровано кілька різних $M$.

\section{Третя задача}

Нелінійна доповлююча задача Коджими---Шиндо була розглянута у \cite{pang-gabriel} і \cite{kanzow}, де $m = 4$, а функція $F$ визначається наступним чином:
\begin{equation}
    F(x_1, x_2, x_3, x_4) = \begin{bmatrix}
        3 x_1^2 + 2 x_1 x_2 + 2 x_2^2 + x_3 + 3 x_4 - 6 \\
        2 x_1^2 + x_1 + x_2^2 + 10 x_3 + 2 x_4 - 2 \\
        3 x_1^2 + x_1 x_2 + 2 x_2^2 + 2 x_3 + 9 x_4 - 9 \\
        x_1^2 + 3 x_2^2 + 2 x_3 + 3 x_4 - 3
    \end{bmatrix}.
\end{equation}

Допустимою множиною знову є ймовірнісний симплекс \[C = \left\{ x \in \RR^4 \middle| x_1 + x_2 + x_3 + x_4 \right\}.\] Для чисельних експериментів ми спершу взяли кілька конкретних стартових точок $x_1 = (1, 1, 1, 1)$ і $x_1 = (0.5, 0.5, 2, 1)$, а потім ще декілька випадкових точок із $C$. Для усіх стартових точок проводилося два тести: один із $\epsilon = 10^{-3}$, второй с $\epsilon = 10^{-6}$.

\begin{remark}
    У цієї задачі неєдиний розв'язок, хоча здебільшого алгоритми збігалися до $x_\star = (1.225, 0, 0, 2.775)$. Втім, не завжди, що і пояснює значну різницю у кількості ітерацій між деякими алгоритмами на деяких тестах.
\end{remark}

\section{Четверта задача}

Цей приклад був розглянутий Суном у \cite{sun}:
\begin{equation}
    \begin{aligned}
        F(x) &= F_1(x) + F_2(x), \\
        F_1(x) &= (f_1(x), f_2(x), \dots, f_m(x)), \\
        F_2(x) &= D x + c, \\
        f_i(x) &= x_{i - 1}^2 + x_i^2 + x_{i - 1} x_i + x_i x_{i + 1}, \quad m = 1, 2, \dots, m, \\
        x_0 &= x_{m + 1} = 0,
    \end{aligned}
\end{equation}
де $D$ --- квадратна $m \times m$ матриця з наступними елементами:
\begin{equation}
    d_{i,j} = \begin{cases}
         1, & j = i - 1, \\
         4, & j = i, \\
        -2, & j = i + 1, \\
         0, & \text{інакше},
    \end{cases}
\end{equation}
$c = (-1, -1, \dots, -1)$. Допустимою множиною є $C = \RR_+^m$, а початкова точка $x_1 = (0, 0, \dots, 0)$. \medskip

Для кращого розуміння наведемо матрицю $D$ для кількох перших $m = 3, 4, 5$:
\begin{equation}
    \begin{pmatrix}
        4 & -2 &  0 \\
        1 &  4 & -2 \\
        0 &  1 &  4
    \end{pmatrix}
    \qquad
    \begin{pmatrix}
        4 & -2 &  0 &  0 \\
        1 &  4 & -2 &  0 \\
        0 &  1 &  4 & -2 \\
        0 &  0 &  1 &  4
    \end{pmatrix}
    \qquad
    \begin{pmatrix}
        4 & -2 &  0 &  0 &  0 \\
        1 &  4 & -2 &  0 &  0 \\
        0 &  1 &  4 & -2 &  0 \\
        0 &  0 &  1 &  4 & -2 \\
        0 &  0 &  0 &  1 &  4
    \end{pmatrix}
\end{equation}

Для усіх чисельних експериментів ми брали $x_1 = (0, \dots, 0)$. Знову ж таки, було розглянуто два значення $\epsilon$: $10^{-3}$ і $10^{-6}$.

\begin{remark}
    Матриця тридіагональна, ми цим скористаємося для ефективного зберігання і множення.
\end{remark}
